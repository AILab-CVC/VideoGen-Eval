<!-- Improved compatibility of back to top link: See: https://github.com/othneildrew/Best-README-Template/pull/73 -->
<a id="readme-top"></a>

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]


<br />
<div align="center">
  <img src="docs/teaser/teaser.png" alt="Logo">

  <h1 align="center">VideoGen-Eval 1.0</h1>

  <p align="center">
    To observe and compare the video quality of recent video generative models!
    <br />
    <a href="https://ailingzeng.site/">Ailing Zeng</a>
    ·
    <a href="https://yyvhang.github.io/">Yuahng Yang</a>
    ·
    <a href="">Weidong Chen</a>
    ·
    <a href="https://scholar.google.com/citations?user=AjxoEpIAAAAJ&hl=en">Wei Liu</a>
    <br />
    <a href="">Project Page</a>
    ·
    <a href="">Technical Report</a>

  </p>
</div>

## Project Updates
- 🔥 **News**: ```2024/10/07```: VideoGen-Eval-1.0 is available, please check the [Project Page]() and [Technical Report]() for more details.

<!-- TABLE OF CONTENTS -->
<details>
  <summary>Table of Contents</summary>
  <ol>
    <li>
      <a href="#about-the-project">About The Project</a>
    </li>
    <li>
      <a href="#assets">Assets</a>
    </li>
    <li><a href="#job-list">Job List</a></li>
    <li><a href="#contributing">Contributing</a></li>
    <li><a href="#license">License</a></li>
    <li><a href="#contact">Contact</a></li>
    <li><a href="#citation">Citation</a></li>
  </ol>
</details>

## About The Project

Recently, models like SORA have advanced generating videos with higher resolution, more natural motion, better vision-language alignment, and increased controllability, particularly for long video sequences. However, despite the emergence of several DiT-based closed-source and open-source models, a comprehensive investigation into their capabilities and limitations remains lacking, creating a noticeablegap between academic research and industry practice. To bridge the existing gap and provide a more profound analysis of recent video generation advancements. In specific, we devise over **700** critical prompts and presenting more than **8,000** cases from closed-source and several open-source models. We systematically examines:

* Impacts on vertical-domain application models;
* Key objective capabilities of video generation models;
* Video generation across eleven application scenarios;
* In-depth discussions on challenges and future research issues showcasing a wealth of qualitative comparisons.

## Assets

The inputs we utilized, including text, images, videos, and the generated results of all models, are open for download: [Google Drive](), [Baidu](https://pan.baidu.com/s/1K0O162lQObjcmO6d9uqffQ?pwd=hqcn). You can also visit the [Website]() to browse these results. We encourage researchers to use our test results for comparison and analysis in specific tasks.

## Job List

- [x] VideoGen-Eval-1.0 released
- [ ] Add results of Seaweed, PixelDance, and MiracleVision.
- [ ] Make the arena for video generation models.

<!-- CONTRIBUTING -->
## Contributing
If you have a suggestion that would make this better, please fork the repo and create a pull request. You can also simply open an issue with the tag "enhancement".
Don't forget to give the project a star! Thanks again!

1. Fork the Project
2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)
3. Commit your Changes (`git commit -m 'Add some change'`)
4. Push to the Branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

### Top contributors:

<a href="https://github.com/AILab-CVC/VideoGen-Eval/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=AILab-CVC/VideoGen-Eval" alt="contrib.rocks image" />
</a>

<!-- LICENSE -->
## License

Distributed under the MIT License. See `LICENSE.txt` for more information.

<!-- CONTACT -->
## Contact

Ailing Zeng - [ailingzengzzz@gmail.com](mailto:ailingzengzzz@gmail.com)

Yuhang Yang - [yyuhang@mail.ustc.edu.cn](mailto:yyuhang@mail.ustc.edu.cn)

## Citation

<!-- ```

``` -->



<!-- MARKDOWN LINKS & IMAGES -->
<!-- https://www.markdownguide.org/basic-syntax/#reference-style-links -->
[contributors-shield]: https://img.shields.io/github/contributors/AILab-CVC/VideoGen-Eval.svg?style=for-the-badge
[contributors-url]: https://github.com/AILab-CVC/VideoGen-Eval/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/AILab-CVC/VideoGen-Eval.svg?style=for-the-badge
[forks-url]: https://github.com/othneildrew/Best-README-Template/network/members
[stars-shield]: https://img.shields.io/github/stars/AILab-CVC/VideoGen-Eval.svg?style=for-the-badge
[stars-url]: https://github.com/AILab-CVC/VideoGen-Eval/stargazers
[issues-shield]: https://img.shields.io/github/issues/AILab-CVC/VideoGen-Eval.svg?style=for-the-badge
[issues-url]: https://github.com/AILab-CVC/VideoGen-Eval/issues
[product-screenshot]: images/screenshot.png
[Next.js]: https://img.shields.io/badge/next.js-000000?style=for-the-badge&logo=nextdotjs&logoColor=white
[Next-url]: https://nextjs.org/
[React.js]: https://img.shields.io/badge/React-20232A?style=for-the-badge&logo=react&logoColor=61DAFB
[React-url]: https://reactjs.org/
[Vue.js]: https://img.shields.io/badge/Vue.js-35495E?style=for-the-badge&logo=vuedotjs&logoColor=4FC08D
[Vue-url]: https://vuejs.org/
[Angular.io]: https://img.shields.io/badge/Angular-DD0031?style=for-the-badge&logo=angular&logoColor=white
[Angular-url]: https://angular.io/
[Svelte.dev]: https://img.shields.io/badge/Svelte-4A4A55?style=for-the-badge&logo=svelte&logoColor=FF3E00
[Svelte-url]: https://svelte.dev/
[Laravel.com]: https://img.shields.io/badge/Laravel-FF2D20?style=for-the-badge&logo=laravel&logoColor=white
[Laravel-url]: https://laravel.com
[Bootstrap.com]: https://img.shields.io/badge/Bootstrap-563D7C?style=for-the-badge&logo=bootstrap&logoColor=white
[Bootstrap-url]: https://getbootstrap.com
[JQuery.com]: https://img.shields.io/badge/jQuery-0769AD?style=for-the-badge&logo=jquery&logoColor=white
[JQuery-url]: https://jquery.com 
